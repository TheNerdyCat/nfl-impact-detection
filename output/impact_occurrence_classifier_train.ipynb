{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NFL First and Future - Impact Detection\n",
    "-------------------\n",
    "# Impact Occurrence Classifier | Train\n",
    "\n",
    "In this notebook, we will train an algorithm to predict the probablity of an impact occurring IN GENERAL for a particular frame in a video. We'll be reducing the problem to a simple binary classification problem. We can however use the results from this algorithm in many ways - either to add as a meta-feature for the final algorithm, or to perform an operation on the final prediction probablities (e.g. multiply the probabilities together).\n",
    "\n",
    " - What data do we have on what kind of play it is? Certain plays are more likely to have collisions. \n",
    " - Cross-validation. When splitting, we should consider game, team, play, AND camera angle.\n",
    "\n",
    "\n",
    "\n",
    "#### CLEANING STEPS:\n",
    " 1. `impactType` - shoulder values\n",
    " - Bin player positions and add as a feature\n",
    " \n",
    " \n",
    "## 1.00 Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data vis packages\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Data prep\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Modelling packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import backend as k\n",
    "# Key layers\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Flatten\n",
    "# Activation layers\n",
    "from tensorflow.keras.layers import ReLU, LeakyReLU, ELU, ThresholdedReLU\n",
    "# Dropout layers\n",
    "from tensorflow.keras.layers import Dropout, AlphaDropout, GaussianDropout\n",
    "# Normalisation layers\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "# Embedding layers\n",
    "from tensorflow.keras.layers import Embedding, Concatenate, Reshape\n",
    "# Callbacks\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, LearningRateScheduler, ModelCheckpoint\n",
    "# Optimisers\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "# Model cross validation and evaluation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "\n",
    "# For Bayesian hyperparameter searching\n",
    "from skopt import gbrt_minimize, gp_minimize\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "REPLICAS: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "strategy = tf.distribute.get_strategy()\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "print(f'REPLICAS: {REPLICAS}')\n",
    "\n",
    "# Data access\n",
    "gpu_options = tf.compat.v1.GPUOptions(allow_growth=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.00 Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_video_labels shape: \t(983885, 14)\n",
      "train_track_data shape: \t(333811, 12)\n",
      "sample_submission shape: \t(56230, 9)\n"
     ]
    }
   ],
   "source": [
    "# Directory and file paths\n",
    "input_dir               = '../input'\n",
    "train_video_labels_path = os.path.join(input_dir, 'train_labels.csv')\n",
    "train_track_data_path   = os.path.join(input_dir, 'train_player_tracking.csv')\n",
    "sample_submission_path  = os.path.join(input_dir, 'sample_submission.csv')\n",
    "\n",
    "# Read in data\n",
    "train_video_labels = pd.read_csv(train_video_labels_path)\n",
    "train_track_data   = pd.read_csv(train_track_data_path)\n",
    "sample_submission  = pd.read_csv(sample_submission_path)\n",
    "\n",
    "del train_video_labels_path, train_track_data_path, sample_submission_path\n",
    "\n",
    "print(f'train_video_labels shape: \\t{train_video_labels.shape}')\n",
    "print(f'train_track_data shape: \\t{train_track_data.shape}')\n",
    "print(f'sample_submission shape: \\t{sample_submission.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: nn_impact_occurrence_classifier_seed14\n"
     ]
    }
   ],
   "source": [
    "# Define key parameters\n",
    "SEED = 14\n",
    "np.random.seed(SEED)\n",
    "\n",
    "SCALER_METHOD = StandardScaler()\n",
    "\n",
    "FEATURE_SELECTOR = RandomForestClassifier(random_state=SEED)\n",
    "\n",
    "NUM_COMPONENTS = 200\n",
    "PCA_METHOD = PCA(n_components=NUM_COMPONENTS, random_state=SEED)\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 64\n",
    "KFOLDS = 10\n",
    "PATIENCE = 10\n",
    "\n",
    "USE_EMBEDDING = True\n",
    "MODEL_TO_USE = 'nn'\n",
    "model_name_save = MODEL_TO_USE + '_impact_occurrence_classifier_seed' + str(SEED)\n",
    "\n",
    "# Create weights path if does not exist already\n",
    "if not os.path.exists(f'models/{model_name_save}'):\n",
    "    os.mkdir(f'models/{model_name_save}')\n",
    "\n",
    "print(f'Model name: {model_name_save}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.00 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets(video_labels, track_data):\n",
    "    \"\"\"\n",
    "    Merges video label features to the player tracking data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------     \n",
    "    video_labels : pd.DataFrame \n",
    "        pd.DataFrame of video label data\n",
    "    track_data : pd.DataFrame\n",
    "        pd.DataFrame of player tracking data\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame of player tracking data with impact label features merged in\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return(merged_track_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
